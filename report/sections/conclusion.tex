\section{Conclusion}
To summarize our contributions, in this work, we demonstrate that the incorporation of scene graph embeddings can provide significant improvement to a simple grounding network. With our approach, we are able to achieve an accuracy that is very close to the state-of-the-art. We also point out an imperfection in the current way of treating multiple groundtruth adopted by the community, and propose to use a more fine-grained way of computing the evaluation metric. For the learning experience, this project has allowed us to gain more insight into machine learning with different modalities and expanded our knowledge in the area of representation learning on graphs. We also recognize the importance of code release with publication and its profound influence in the reproducibility of published results. In terms of work split, Alex focused on the implementation of Graph R-CNN, training and tuning on Visual Genome, and generating scene graph embeddings for the Flickr30k Entities dataset, while Cathy implemented the grounding framework and conducted various experiments with scene graph embeddings, sentence graphs and multi-instance grounding. Although our work seem to be on separate paths, we had many meaningful discussions when it came to bottlenecks for our own parts that were indispensable to this project.